Excellent ğŸ‘Œ â€” this **`locals` block** is the foundation for your Terraform GCP VM setup.

It dynamically computes and structures **instance names, disk names, IP configurations, and zone assignments**, making the rest of your Terraform configuration **cleaner and reusable**.

Letâ€™s break down and explain **each local variable** in this section step by step:

---

## ğŸ§© LOCALS BLOCK EXPLAINED IN DETAIL

```hcl
locals {
  external_ip_add = var.enable_external_ip ? 1 : 0
  access_config   = local.external_ip_add != 0 ? [true] : []

  shielded_vm_configs = var.enable_shielded_vm ? [true] : []

  instance_name = [
    for i in range(1, var.instance_count + 1) :
    format("%s%d", var.machine_name, i)
  ]

  disk_name = [
    for idx, name in local.instance_name :
    [for i in range(1, var.attached_disk_per_instance + 1) :
      format("%s-persistent-disk%d", name, i)
    ]
  ]

  attached_disk_names = flatten(local.disk_name)

  instance = flatten([
    for idx, name in local.instance_name :
    [for i in range(1, var.attached_disk_per_instance + 1) : name]
  ])

  zones = flatten([
    for idx, zone in range(var.instance_count) :
    [for i in range(var.attached_disk_per_instance) :
      element(var.machine_zone, zone % length(var.machine_zone))
    ]
  ])
}
```

---

### ğŸŸ¢ 1ï¸âƒ£ `external_ip_add`

```hcl
external_ip_add = var.enable_external_ip ? 1 : 0
```

âœ… **Purpose:**

* Checks whether external IP creation is enabled (`var.enable_external_ip`).
* If true â†’ returns `1`
* If false â†’ returns `0`

ğŸ“˜ **Why:**
This allows you to conditionally create `google_compute_address` (external IP resource) only when needed.

---

### ğŸŸ¢ 2ï¸âƒ£ `access_config`

```hcl
access_config = local.external_ip_add != 0 ? [true] : []
```

âœ… **Purpose:**

* Used inside the VMâ€™s `network_interface` block.
* If external IP is enabled â†’ returns `[true]`
* Else â†’ returns `[]` (empty list)

ğŸ“˜ **Why:**
Terraform uses this pattern for dynamic blocks:

```hcl
dynamic "access_config" {
  for_each = local.access_config
  content {
    nat_ip = google_compute_address.static_external_ip_address[0].address
  }
}
```

â†’ If `[true]`, the dynamic block is rendered once.
â†’ If `[]`, it is skipped completely.

---

### ğŸŸ¢ 3ï¸âƒ£ `shielded_vm_configs`

```hcl
shielded_vm_configs = var.enable_shielded_vm ? [true] : []
```

âœ… **Purpose:**

* Enables **Shielded VM** options (secure boot, vTPM, integrity monitoring).
* Returns `[true]` if enabled, `[]` if not.

ğŸ“˜ **Why:**
Used in a dynamic block like:

```hcl
dynamic "shielded_instance_config" {
  for_each = local.shielded_vm_configs
  content {
    enable_secure_boot = true
    enable_vtpm = true
    enable_integrity_monitoring = true
  }
}
```

If Shielded VM is disabled, this block wonâ€™t be included at all.

---

### ğŸŸ¢ 4ï¸âƒ£ `instance_name`

```hcl
instance_name = [
  for i in range(1, var.instance_count + 1) :
  format("%s%d", var.machine_name, i)
]
```

âœ… **Purpose:**
Automatically generate VM names like:

```
myvm1, myvm2, myvm3 ...
```

ğŸ“˜ **Why:**
You avoid manually naming every instance.
`var.machine_name` could be `"gce-vm"`, and if `var.instance_count = 3`, this results in:

```
["gce-vm1", "gce-vm2", "gce-vm3"]
```

---

### ğŸŸ¢ 5ï¸âƒ£ `disk_name`

```hcl
disk_name = [
  for idx, name in local.instance_name :
  [for i in range(1, var.attached_disk_per_instance + 1) :
    format("%s-persistent-disk%d", name, i)
  ]
]
```

âœ… **Purpose:**
Generates disk names for each VM based on:

* Instance name
* Number of attached disks per instance

ğŸ“˜ **Example:**
If `attached_disk_per_instance = 2` and instance names are:

```
["gce-vm1", "gce-vm2"]
```

Then `disk_name` becomes:

```
[
  ["gce-vm1-persistent-disk1", "gce-vm1-persistent-disk2"],
  ["gce-vm2-persistent-disk1", "gce-vm2-persistent-disk2"]
]
```

---

### ğŸŸ¢ 6ï¸âƒ£ `attached_disk_names`

```hcl
attached_disk_names = flatten(local.disk_name)
```

âœ… **Purpose:**
Converts nested lists into a single flat list.

ğŸ“˜ **Example:**
From:

```
[
  ["gce-vm1-persistent-disk1", "gce-vm1-persistent-disk2"],
  ["gce-vm2-persistent-disk1", "gce-vm2-persistent-disk2"]
]
```

â†’ to:

```
["gce-vm1-persistent-disk1", "gce-vm1-persistent-disk2", "gce-vm2-persistent-disk1", "gce-vm2-persistent-disk2"]
```

---

### ğŸŸ¢ 7ï¸âƒ£ `instance`

```hcl
instance = flatten([
  for idx, name in local.instance_name :
  [for i in range(1, var.attached_disk_per_instance + 1) : name]
])
```

âœ… **Purpose:**
Repeats each instance name for every attached disk it has.

ğŸ“˜ **Example:**
If `instance_name = ["vm1", "vm2"]` and each has `2` disks:

```
instance = ["vm1", "vm1", "vm2", "vm2"]
```

ğŸ“— **Usage:**
Used to map each disk back to its VM in an attachment resource:

```hcl
instance = local.instance[count.index]
```

---

### ğŸŸ¢ 8ï¸âƒ£ `zones`

```hcl
zones = flatten([
  for idx, zone in range(var.instance_count) :
  [for i in range(var.attached_disk_per_instance) :
    element(var.machine_zone, zone % length(var.machine_zone))
  ]
])
```

âœ… **Purpose:**
Assigns each disk a **zone** in a round-robin fashion from `var.machine_zone`.

ğŸ“˜ **Example:**
If:

```hcl
machine_zone = ["us-central1-a", "us-central1-b"]
instance_count = 3
attached_disk_per_instance = 2
```

Then output:

```
["us-central1-a", "us-central1-a", "us-central1-b", "us-central1-b", "us-central1-a", "us-central1-a"]
```

â†’ Ensures disks are spread evenly across available zones.

---

## ğŸ§  Summary Table


| Local Variable        | Purpose                                                   | Example Output                                         |
| --------------------- | --------------------------------------------------------- | ------------------------------------------------------ |
| `external_ip_add`     | Controls whether to create external IPs                   | `1`or`0`                                               |
| `access_config`       | Used for dynamic external IP config in`network_interface` | `[true]`or`[]`                                         |
| `shielded_vm_configs` | Toggles Shielded VM configuration block                   | `[true]`or`[]`                                         |
| `instance_name`       | Generates VM names                                        | `["vm1", "vm2", "vm3"]`                                |
| `disk_name`           | Generates disk names per VM                               | `[["vm1-persistent-disk1"], ["vm2-persistent-disk1"]]` |
| `attached_disk_names` | Flattens all disk names                                   | `["vm1-persistent-disk1", "vm2-persistent-disk1"]`     |
| `instance`            | Repeats VM names per disk                                 | `["vm1", "vm1", "vm2", "vm2"]`                         |
| `zones`               | Distributes zones round-robin                             | `["us-central1-a", "us-central1-b", "us-central1-a"]`  |

---

## ğŸ§± How This Fits Into the Whole Terraform File

These locals are later used in:

* `google_compute_instance` â†’ for `name`, `zone`, and dynamic blocks.
* `google_compute_disk` â†’ for naming and zoning disks.
* `google_compute_attached_disk` â†’ to map disks to VMs.
* `google_compute_address` â†’ for conditional creation of IPs.

âœ… This block makes your Terraform **modular**, **dynamic**, and **scalable** â€”
you can change `instance_count` or `attached_disk_per_instance` and Terraform auto-calculates everything else.

---

## ğŸ§© Resource: `google_compute_resource_policy.snapshot_policy`

This creates a **snapshot policy** in Google Cloud.
Snapshot policies define **how often** and **how long** disk snapshots are retained.

---

### ğŸ“„ Full Breakdown

```hcl
resource "google_compute_resource_policy" "snapshot_policy" {
  name = var.policy_name

  snapshot_schedule_policy {
    schedule {
      hourly_schedule {
        hours_in_cycle = 23
        start_time     = var.utc_time # In UTC
      }
    }

    retention_policy {
      max_retention_days    = var.retention_days
      on_source_disk_delete = "KEEP_AUTO_SNAPSHOTS"
    }

    snapshot_properties {
      storage_locations = [var.storage_locations]
    }
  }
}
```

---

### ğŸ§  Step-by-Step Explanation

#### ğŸ”¹ 1. `name = var.policy_name`

* The **name** of the snapshot policy in GCP.
* Taken from a variable â†’ allows flexibility for different policies in different environments.

ğŸ“˜ Example:

```hcl
policy_name = "daily-snapshot-policy"
```

---

#### ğŸ”¹ 2. `snapshot_schedule_policy`

This block defines how and when snapshots are automatically created.

##### `schedule { hourly_schedule { ... } }`

```hcl
hourly_schedule {
  hours_in_cycle = 23
  start_time     = var.utc_time
}
```

* **`hours_in_cycle = 23`** â†’ Snapshots are taken every 23 hours.
* **`start_time`** â†’ Defines when the first snapshot cycle starts (in **UTC time**, not your local time).

ğŸ“˜ Example:

```hcl
utc_time = "03:00" # Snapshots start at 3 AM UTC daily
```

You can also change this to use `daily_schedule` or `weekly_schedule` if needed.

---

#### ğŸ”¹ 3. `retention_policy`

```hcl
retention_policy {
  max_retention_days    = var.retention_days
  on_source_disk_delete = "KEEP_AUTO_SNAPSHOTS"
}
```

* **`max_retention_days`** â†’ Number of days to keep snapshots before auto-deletion.
* **`on_source_disk_delete = "KEEP_AUTO_SNAPSHOTS"`** â†’ If the source disk is deleted, existing snapshots are **not deleted**.

ğŸ“˜ Example:

```hcl
retention_days = 7  # Keep snapshots for 7 days
```

---

#### ğŸ”¹ 4. `snapshot_properties`

```hcl
snapshot_properties {
  storage_locations = [var.storage_locations]
}
```

* Defines where the snapshots are stored (region/multi-region).
* Usually something like `"us"` or `"asia"` or `"us-central1"`.

ğŸ“˜ Example:

```hcl
storage_locations = "us"
```

---

## ğŸ§± Variables Used

These variables are defined separately to make the policy reusable across environments.

```hcl
variable "policy_name" {
  description = "Policy Name"
}

variable "utc_time" {
  description = "UTC Time"
}

variable "retention_days" {
  description = "Retention time in day"
}

variable "storage_locations" {
  description = "Storage location"
}
```

### ğŸ“˜ Example Values

You can define them in your `terraform.tfvars`:

```hcl
policy_name       = "auto-snapshot-policy"
utc_time          = "03:00"
retention_days    = 7
storage_locations = "us"
```

---

## ğŸ§  Summary Table


| Block                 | Purpose                               | Example                        |
| --------------------- | ------------------------------------- | ------------------------------ |
| `name`                | Name of the snapshot policy           | `"auto-snapshot-policy"`       |
| `hourly_schedule`     | Defines frequency (every 23 hours)    | `"03:00"`start time            |
| `retention_policy`    | Defines retention and delete behavior | `7 days`,`KEEP_AUTO_SNAPSHOTS` |
| `snapshot_properties` | Defines snapshot storage region       | `"us"`or`"asia"`               |

---

## âœ… What Happens After You Apply This

Once you apply this Terraform resource:

* GCP will **automatically take snapshots** of attached disks according to the schedule.
* The snapshots will be **retained for the defined number of days**.
* If you attach this policy to a disk (using `google_compute_disk_resource_policy_attachment`), the disk will **automatically follow** this snapshot rule.

---



```
User@DESKTOP-KM01E29 MINGW64 ~/Desktop/HDFC/Projects/YBA_Database_Deployment_Automation/YBA_Terraform_Cluster_V1_Success (main)
$ gcloud compute addresses delete yba-int-ip-1 --region=us-central1 --quiet
Deleted [https://www.googleapis.com/compute/v1/projects/apt-index-474313-e9/regions/us-central1/addresses/yba-int-ip-1].

User@DESKTOP-KM01E29 MINGW64 ~/Desktop/HDFC/Projects/YBA_Database_Deployment_Automation/YBA_Terraform_Cluster_V1_Success (main)
$

```


### gcloud compute addresses delete yb-db-int-ip-1 --region=us-central1 --quiet
